{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Theory of PCA with example"
      ],
      "metadata": {
        "id": "v0qaPGAGc-7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(PCA) is a dimensionality reduction method that keeps the majority of the crucial information in complicated datasets while making them simpler. The way it operates is by converting the initial variables into a new set of main components, which are orthogonal variables. The first component captures the maximum variance, followed by the second, in the order of how much variance in the data they explain.\n",
        "Let's say we wish to use PCA to reduce a dataset that contains two features—weight and height—to only one dimension. PCA finds two eigenvectors and computes the covariance matrix after normalizing the input. The direction of the maximum variance in the data is represented by the eigenvector with the highest eigenvalue. The original data is then projected onto this eigenvector by PCA to create a one-dimensional representation of the dataset.\n"
      ],
      "metadata": {
        "id": "a45X8qmqdEBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "gv-xRcDtZRyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X_iris = iris.data\n",
        "y_iris = iris.target"
      ],
      "metadata": {
        "id": "2tmV5TiHZ5e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "phx-BkfsaGZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_iris_without_pca = RandomForestClassifier(random_state=42)\n",
        "model_iris_without_pca.fit(X_train_iris, y_train_iris)\n",
        "y_pred_iris_without_pca = model_iris_without_pca.predict(X_test_iris)\n",
        "accuracy_iris_without_pca = accuracy_score(y_test_iris, y_pred_iris_without_pca)\n",
        "print(\"Accuracy without PCA on Iris dataset:\", accuracy_iris_without_pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWDETfu-aQqT",
        "outputId": "2b5bab75-f31e-4afb-c9ba-227f5bebd88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without PCA on Iris dataset: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_iris = StandardScaler()\n",
        "X_train_scaled_iris = scaler_iris.fit_transform(X_train_iris)\n",
        "X_test_scaled_iris = scaler_iris.transform(X_test_iris)\n",
        "pca_iris = PCA(n_components=2)\n",
        "X_train_pca_iris = pca_iris.fit_transform(X_train_scaled_iris)\n",
        "X_test_pca_iris = pca_iris.transform(X_test_scaled_iris)"
      ],
      "metadata": {
        "id": "21sUidoDaYK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_iris_with_pca = RandomForestClassifier(random_state=42)\n",
        "model_iris_with_pca.fit(X_train_pca_iris, y_train_iris)\n",
        "y_pred_iris_with_pca = model_iris_with_pca.predict(X_test_pca_iris)\n",
        "accuracy_iris_with_pca = accuracy_score(y_test_iris, y_pred_iris_with_pca)\n",
        "print(\"Accuracy with PCA on Iris dataset:\", accuracy_iris_with_pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjybuqVnaepD",
        "outputId": "1fbff706-dd9a-43ad-ffb6-aeb98b1ff8e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with PCA on Iris dataset: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_custom_without_pca = RandomForestClassifier(random_state=42)\n",
        "model_custom_without_pca.fit(X_train_custom, y_train_custom)\n",
        "y_pred_custom_without_pca = model_custom_without_pca.predict(X_test_custom)\n",
        "accuracy_custom_without_pca = accuracy_score(y_test_custom, y_pred_custom_without_pca)\n",
        "print(\"Accuracy without PCA on custom dataset:\", accuracy_custom_without_pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCc3AMBjamrR",
        "outputId": "c97c20f8-1b78-4d51-9764-4679a7525a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without PCA on custom dataset: 0.9435897435897436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_custom = StandardScaler()\n",
        "X_train_scaled_custom = scaler_custom.fit_transform(X_train_custom)\n",
        "X_test_scaled_custom = scaler_custom.transform(X_test_custom)\n",
        "pca_custom = PCA(n_components=2)\n",
        "X_train_pca_custom = pca_custom.fit_transform(X_train_scaled_custom)\n",
        "X_test_pca_custom = pca_custom.transform(X_test_scaled_custom)"
      ],
      "metadata": {
        "id": "vXXtR_TSau1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_custom_with_pca = RandomForestClassifier(random_state=42)\n",
        "model_custom_with_pca.fit(X_train_pca_custom, y_train_custom)\n",
        "y_pred_custom_with_pca = model_custom_with_pca.predict(X_test_pca_custom)\n",
        "accuracy_custom_with_pca = accuracy_score(y_test_custom, y_pred_custom_with_pca)\n",
        "print(\"Accuracy with PCA on custom dataset:\"), accuracy_custom_with_pca"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9oDvieZa4MY",
        "outputId": "9d5d5c80-cdf4-4891-9b1f-403d0ae3eee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with PCA on custom dataset:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 0.2762820512820513)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyse the result. Write in brief a paragraph on your observations.**"
      ],
      "metadata": {
        "id": "c-KT2_XicL6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "it's evident that the models perform exceptionally well on the Iris dataset, achieving a perfect accuracy of 1.0 without PCA and a high accuracy of 0.9 with PCA. This suggests that the Iris dataset is relatively well-structured and easily separable by the chosen RandomForestClassifier model. On the other hand, the custom dataset presents a more challenging task, with an accuracy of 0.9436 without PCA. However, with PCA applied, the accuracy drops significantly to 0.2763. This drastic reduction in accuracy indicates that PCA might not be suitable for this particular custom dataset. It's possible that the dataset's features do not exhibit strong correlations or that the dimensionality reduction caused by PCA results in a loss of crucial information for accurate classification. Further analysis and experimentation may be required to improve the model's performance on the custom dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GFCZfQrzcX9P"
      }
    }
  ]
}